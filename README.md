# SmartChat-Routing

A local chatbot application powered by **LLaMA models** and **ChromaDB** for memory.  
It features a **Tkinter-based UI**, multimodel routing, and persistent user profiles.  

---

## ğŸš€ Features
- Tkinter UI for easy interaction  
- Local LLaMA model inference via [llama-cpp-python](https://github.com/abetlen/llama-cpp-python)  
- ChromaDB vector memory for context retrieval  
- User profile management stored in JSON  
- Chat logging for tracking conversation history  
- Modular structure (router, loader, memory, etc.)  
- Multimodel routing for specialized handling of different tasks  

---

## âš™ï¸ Installation

### 1. Clone the Repository
git clone https://github.com/yourusername/CHAT_BOT.git
cd CHAT_BOT

### 2. Create a Virtual Environment (Recommended)

python -m venv venv
source venv/bin/activate   # On Linux/Mac
venv\Scripts\activate      # On Windows

### 3. Install Dependencies

pip install -r requirements.txt

### 4. Download Models

Inside the Models/ folder, youâ€™ll find model download links.txt.
Follow the instructions to download the required .gguf model files and place them in the Models/ directory.

---

## â–¶ï¸ Usage

python main.py


This will launch the Tkinter-based GUI where you can start chatting with the bot.

---

## ğŸ› ï¸ Requirements

Python 3.9+

At least 8 GB RAM recommended (more for larger LLaMA models)

A CPU/GPU supported by llama-cpp-python

---

## ğŸ“– How It Works

1. Model Loading
      - loader.py initializes the LLaMA model from the Models/ directory.

2. Memory
      - memory.py uses ChromaDB to store embeddings of conversations, allowing the bot to â€œrememberâ€ past chats.

3. Routing & Multimodel Support
      - router.py decides how to process user input.
      - The bot can use multiple models simultaneously, each optimized for a different task:
      - A smaller, faster model can handle casual or short interactions.
      - A larger, more capable model is used for reasoning, summarization, or complex queries.
      - The routing logic determines which model to call based on the type of user request.

4. Logging
      - chat_logger.py saves all conversations for later review.

5. Profiles
      - profile_manager.py loads and saves settings in user_profile.json.

6. UI
      - ui.py provides a simple Tkinter window for chatting.

---

## ğŸ¤ Contributing

1. Fork this repository
2. Create a new branch (git checkout -b feature-xyz)
3. Make your changes
4. Commit (git commit -m 'Add new feature')
5. Push (git push origin feature-xyz)
6. Open a Pull Request

---

## ğŸ“‚ Project Structure

```plaintext
CHAT_BOT/
â”‚â”€â”€ chat_logger.py          # Handles logging of chats
â”‚â”€â”€ loader.py               # Loads models and embeddings
â”‚â”€â”€ main.py                 # Entry point for running the chatbot
â”‚â”€â”€ memory.py               # Manages memory storage and retrieval with ChromaDB
â”‚â”€â”€ profile_manager.py      # Handles user profiles
â”‚â”€â”€ router.py               # Routes user inputs to appropriate handlers or models
â”‚â”€â”€ ui.py                   # Tkinter-based user interface
â”‚â”€â”€ user_profile.json       # Stores user preferences/profile data
â”‚
â”œâ”€â”€ Models/
â”‚   â””â”€â”€ model download links.txt   # Instructions/links for downloading models
â”‚
â””â”€â”€ requirements.txt        # Python dependencies
